# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qHPYPgJMBWFCB9a-jI7Xeiu3UIlWJZ1V
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os
zip_path = '/content/drive/MyDrive/my_dataset.zip'

extract_path = '/content/dataset'

# Unzip it
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Dataset unzipped successfully!")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = '/content/dataset/dataset/DATASET/TRAIN'
test_dir = '/content/dataset/dataset/DATASET/TEST'

# Set up the Training Data Generator
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalize pixel values from 0-255 to 0-1
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.2 # Automatically save 20% of data for validation
)

# Set up the Test Data Generator
test_datagen = ImageDataGenerator(rescale=1./255)

# Create the generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224), # MobileNetV2 was trained on 224x224 images
    batch_size=32,
    class_mode='binary',   # Our problem is "O" (organic) or "R" (recyclable)
    subset='training'      # This is the training part
)

validation_generator = train_datagen.flow_from_directory(
    train_dir, # Same directory
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    subset='validation'    # This is the validation part
)

# --- Test Generator (for final evaluation) ---
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary',
    shuffle=False  # Important: Don't shuffle test data
)

print("---")
print("Data generators created successfully!")

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout

# 1. Load the base model (MobileNetV2)
# We use 'imagenet' weights: these are weights from it being trained on millions of images.
# include_top=False: This is the MOST important part. It means "don't load the final layer."
base_model = MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet'
)

# 2. Freeze the base model
# We tell Keras not to update the weights of these layers during training.
base_model.trainable = False

# 3. Create your new model on top
model = Sequential([
    base_model,                     # The frozen MobileNetV2 base
    GlobalAveragePooling2D(),       # This efficiently flattens the output of the base model
    Dropout(0.2),                   # A dropout layer to help prevent overfitting
    Dense(1, activation='sigmoid')  # A single final neuron. 'sigmoid' is used for
                                    # binary (0 or 1) classification.
])

# 4. Compile the model
# We tell it how to learn (optimizer) and how to measure success (loss)
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Let's see our model structure
print(model.summary())

# Let's set the number of epochs (how many times to go over the data)
EPOCHS = 10

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // 32,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // 32,
    epochs=EPOCHS
)

print("Model training complete!")

import numpy as np

# 1. Create a representative dataset for quantization
# TFLite needs to see a sample of your data to figure out the best way
# to convert the 32-bit floats to 8-bit integers.
representative_data = []
# We'll take 100 batches from our training generator
for input_batch, _ in train_generator:
    representative_data.append(input_batch)
    if len(representative_data) >= 100:
        break

# This function tells the converter how to get the data
def representative_dataset_gen():
    for data in representative_data:
        yield [data.astype(np.float32)]

# 2. Set up the TFLite Converter
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# 3. Enable optimizations (this turns on quantization)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# 4. Provide the representative dataset
converter.representative_dataset = representative_dataset_gen

# 5. Ensure 8-bit integer input/output (common for edge devices)
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,
    tf.lite.OpsSet.TFLITE_BUILTINS # Fallback
]
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8 # or tf.uint8

# 6. Convert the model
tflite_model_quant = converter.convert()

# 7. Save the model to a file
tflite_model_file = 'model.tflite'
with open(tflite_model_file, 'wb') as f:
    f.write(tflite_model_quant)

print(f"Successfully converted and saved model to {tflite_model_file}")

from google.colab import files

# Prompt your browser to download the file
files.download(tflite_model_file)